{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (5.1.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras==2.2.4) (1.2.1)\n",
      "Requirement already satisfied: cached-property in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from h5py->keras==2.2.4) (1.5.2)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "Successfully installed keras-2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "  Using cached tensorflow-1.14.0-cp37-cp37m-win_amd64.whl (68.3 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (3.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (0.4.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "  Using cached tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.34.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.19.5)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "  Using cached tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorflow==1.14.0) (1.1.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14.0) (1.5.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.5.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.5.0\n",
      "    Uninstalling tensorflow-estimator-2.5.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.5.0\n",
      "    Uninstalling tensorflow-2.5.0:\n",
      "      Successfully uninstalled tensorflow-2.5.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mallarapu shiva sai\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4\n",
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers \n",
    "\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the path of the data(train,test,validaton)\n",
    "train=(r\"C:\\Users\\mallarapu shiva sai\\Downloads\\archive\\chest_xray\\train\")\n",
    "test=(r\"C:\\Users\\mallarapu shiva sai\\Downloads\\archive\\chest_xray\\test\")\n",
    "val=(r\"C:\\Users\\mallarapu shiva sai\\Downloads\\archive\\chest_xray\\val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are using tensorflow backend v  ,so we go for channel_last ie to specify the channel value as the last dimension in shape of the input.\n",
    "img_width,img_height= 150,150\n",
    "input_shape = (img_width,img_height,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator-Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Here we import images directly from Directory by using flow_from_directory method.\n",
    "#flow_from_directory() automatically infers the labels from the directory structure of the folders containing images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=16,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#It’s just a thing function that you use to get the output of node. It is also known as Transfer Function.\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# The number of filters are 32 and the kernal_size is (3,3)\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mallarapu shiva sai\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Here we use RMSPROP optimizer and BINARY_CROSSENTROPY as loss function  \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 163s 500ms/step - loss: 0.5494 - acc: 0.7676 - val_loss: 1.3176 - val_acc: 0.5625\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 147s 449ms/step - loss: 0.3107 - acc: 0.8769 - val_loss: 0.3454 - val_acc: 0.7500\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 144s 443ms/step - loss: 0.2678 - acc: 0.9032 - val_loss: 0.4760 - val_acc: 0.6875\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 144s 441ms/step - loss: 0.2242 - acc: 0.9160 - val_loss: 0.3439 - val_acc: 0.8125\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 151s 462ms/step - loss: 0.2057 - acc: 0.9250 - val_loss: 0.5896 - val_acc: 0.6875\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 148s 453ms/step - loss: 0.2056 - acc: 0.9229 - val_loss: 0.7294 - val_acc: 0.7500\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 142s 436ms/step - loss: 0.1861 - acc: 0.9333 - val_loss: 0.9022 - val_acc: 0.6250\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 147s 451ms/step - loss: 0.1844 - acc: 0.9354 - val_loss: 0.5847 - val_acc: 0.6875\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 181s 556ms/step - loss: 0.1935 - acc: 0.9321 - val_loss: 1.0506 - val_acc: 0.7500\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 223s 684ms/step - loss: 0.1962 - acc: 0.9387 - val_loss: 1.4295 - val_acc: 0.6250\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 265s 813ms/step - loss: 0.1818 - acc: 0.9360 - val_loss: 1.5483 - val_acc: 0.6250\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 417s 1s/step - loss: 0.1855 - acc: 0.9415 - val_loss: 0.7453 - val_acc: 0.7500\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 313s 960ms/step - loss: 0.1704 - acc: 0.9438 - val_loss: 1.3030 - val_acc: 0.6250\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 307s 941ms/step - loss: 0.1768 - acc: 0.9423 - val_loss: 0.6399 - val_acc: 0.6875\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 302s 927ms/step - loss: 0.1658 - acc: 0.9446 - val_loss: 1.9839 - val_acc: 0.6875\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 303s 929ms/step - loss: 0.1665 - acc: 0.9452 - val_loss: 1.0397 - val_acc: 0.7500\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 301s 923ms/step - loss: 0.1614 - acc: 0.9488 - val_loss: 2.4603 - val_acc: 0.6250\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 303s 930ms/step - loss: 0.1651 - acc: 0.9469 - val_loss: 3.3307 - val_acc: 0.6875\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 303s 931ms/step - loss: 0.1877 - acc: 0.9411 - val_loss: 1.1644 - val_acc: 0.7500\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 304s 932ms/step - loss: 0.1706 - acc: 0.9450 - val_loss: 1.5099 - val_acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d26c28e400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=5217 // 16,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=17 // 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model in H5 format.\n",
    "model.save('pneumonia.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape not found\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(150,150))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        #if(np.max(img)>1):\n",
    "         #   img = img/255.0\n",
    "        prediction = model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction = model.predict_classes(img)\n",
    "        print(prediction)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n",
    "\n",
    "frame=cv2.imread(\"test.jpg\")\n",
    "data = detect(frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
